{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2020-11-13\n",
      "                                          name  \\\n",
      "0                               Therefore I Am   \n",
      "1                                    positions   \n",
      "2                                       Dakiti   \n",
      "3    Lemonade (feat. Gunna, Don Toliver & NAV)   \n",
      "4                       Mood (feat. iann dior)   \n",
      "..                                         ...   \n",
      "195                          Tennessee Whiskey   \n",
      "196      FRANCHISE (feat. Young Thug & M.I.A.)   \n",
      "197                                    Off Dat   \n",
      "198                                   Bankroll   \n",
      "199                              Conversations   \n",
      "\n",
      "                                     album           artist release_date  \\\n",
      "0                           Therefore I Am    Billie Eilish   2020-11-12   \n",
      "1                                Positions    Ariana Grande   2020-10-30   \n",
      "2                                   Dakiti        Bad Bunny   2020-10-30   \n",
      "3                             B4 The Storm   Internet Money   2020-08-28   \n",
      "4                   Mood (feat. iann dior)         24kGoldn   2020-07-24   \n",
      "..                                     ...              ...          ...   \n",
      "195                              Traveller  Chris Stapleton   2015-05-04   \n",
      "196  FRANCHISE (feat. Young Thug & M.I.A.)     Travis Scott   2020-09-25   \n",
      "197                     Pluto x Baby Pluto           Future   2020-11-13   \n",
      "198                     Pluto x Baby Pluto           Future   2020-11-13   \n",
      "199                      Legends Never Die       Juice WRLD   2020-07-10   \n",
      "\n",
      "     length  popularity  danceability  acousticness  danceability  energy  \\\n",
      "0    174321          95         0.889       0.21800         0.889   0.340   \n",
      "1    172324          97         0.737       0.46800         0.737   0.802   \n",
      "2    205090         100         0.731       0.40100         0.731   0.573   \n",
      "3    195428          90         0.800       0.25000         0.800   0.658   \n",
      "4    140525          98         0.700       0.22100         0.700   0.722   \n",
      "..      ...         ...           ...           ...           ...     ...   \n",
      "195  293293          79         0.392       0.20500         0.392   0.370   \n",
      "196  202794          84         0.835       0.00671         0.835   0.699   \n",
      "197  184736          68         0.898       0.01540         0.898   0.641   \n",
      "198  186846          68         0.830       0.13300         0.830   0.735   \n",
      "199  181661          82         0.747       0.17600         0.747   0.622   \n",
      "\n",
      "     instrumentalness  liveness  loudness  speechiness    tempo  \\\n",
      "0            0.130000    0.0550    -7.773       0.0697   94.009   \n",
      "1            0.000000    0.0931    -4.771       0.0878  144.015   \n",
      "2            0.000052    0.1130   -10.059       0.0544  109.928   \n",
      "3            0.000000    0.1110    -6.142       0.0790  140.042   \n",
      "4            0.000000    0.2720    -3.558       0.0369   90.989   \n",
      "..                ...       ...       ...          ...      ...   \n",
      "195          0.009600    0.0821   -10.888       0.0298   48.718   \n",
      "196          0.000000    0.1950    -5.405       0.2770  154.981   \n",
      "197          0.000000    0.6650    -7.673       0.2970  151.937   \n",
      "198          0.000000    0.2160    -5.230       0.3010  139.932   \n",
      "199          0.000000    0.1510    -5.825       0.0838  159.930   \n",
      "\n",
      "     time_signature  start_date    end_date  \n",
      "0                 4  2020-11-13  2020-11-20  \n",
      "1                 4  2020-11-13  2020-11-20  \n",
      "2                 4  2020-11-13  2020-11-20  \n",
      "3                 4  2020-11-13  2020-11-20  \n",
      "4                 4  2020-11-13  2020-11-20  \n",
      "..              ...         ...         ...  \n",
      "195               4  2020-11-13  2020-11-20  \n",
      "196               4  2020-11-13  2020-11-20  \n",
      "197               4  2020-11-13  2020-11-20  \n",
      "198               4  2020-11-13  2020-11-20  \n",
      "199               4  2020-11-13  2020-11-20  \n",
      "\n",
      "[200 rows x 18 columns]\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    client_id = open('client_id.txt').read()\n",
    "    client_secret = open('client_secret.txt').read()\n",
    "except:\n",
    "    print(\"error\")\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "def getTrackFeatures(id):\n",
    "  meta = sp.track(id)\n",
    "  features = sp.audio_features(id)\n",
    "\n",
    "  # meta\n",
    "  name = meta['name']\n",
    "  album = meta['album']['name']\n",
    "  artist = meta['album']['artists'][0]['name']\n",
    "  release_date = meta['album']['release_date']\n",
    "  length = meta['duration_ms']\n",
    "  popularity = meta['popularity']\n",
    "\n",
    "  # features\n",
    "  acousticness = features[0]['acousticness']\n",
    "  danceability = features[0]['danceability']\n",
    "  energy = features[0]['energy']\n",
    "  instrumentalness = features[0]['instrumentalness']\n",
    "  liveness = features[0]['liveness']\n",
    "  loudness = features[0]['loudness']\n",
    "  speechiness = features[0]['speechiness']\n",
    "  tempo = features[0]['tempo']\n",
    "  time_signature = features[0]['time_signature']\n",
    "\n",
    "  track = [name, album, artist, release_date, length, popularity, danceability, acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, tempo, time_signature]\n",
    "  return track\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(os.getcwd()+'/top200_data'):\n",
    "    \n",
    "    if  filename == os.getcwd() + '/top200_data/data.csv': continue\n",
    "    \n",
    "    start_date = filename[19:29]\n",
    "    end_date = filename[31:41]\n",
    "    data = pd.read_csv('data.csv')\n",
    "    top = pd.read_csv(os.getcwd()+'/top200_data/'+filename)\n",
    "    temp = top.URL\n",
    "        \n",
    "    tracks = []\n",
    "\n",
    "    for url in temp:\n",
    "        track = getTrackFeatures(url[31:])\n",
    "        tracks.append(track)\n",
    "\n",
    "    temp = pd.DataFrame(tracks, columns = ['name', 'album', 'artist', 'release_date', 'length', 'popularity', 'danceability', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'time_signature'])\n",
    "        \n",
    "    temp['start_date'] = start_date\n",
    "    temp['end_date'] = end_date\n",
    "    temp = data.append(temp)\n",
    "    \n",
    "    temp.to_csv(\"/top200_data/data.csv\", sep = ',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'README.md', 'client_id.txt', 'client_secret.txt', 'data.csv', 'final.ipynb', 'regional-global-weekly-latest.csv', 'spotify_data_extraction.ipynb', 'top200_data']\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dc07249f74ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     data = pd.read_csv('data.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
